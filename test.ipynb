{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aces.environement.p3.aces_p3 import ACES_p3\n",
    "from transformers import HfArgumentParser, TrainingArguments, set_seed, DataCollatorForSeq2Seq\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "\n",
    "@dataclass\n",
    "class AcesArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.DataTrainingArguments\n",
    "    \"\"\"\n",
    "\n",
    "    environement_name : str = field( default = \"p3\", metadata={\"help\": \"environment name\"})\n",
    "    path_archive : str = field( default = \"/home/flowers/work/aces/aces/environement/p3/preprocess_p3_emb_dedup_puzzles.json\", metadata={\"help\": \"path to the archive\"})\n",
    "    num_solutions: int = field( default = 10, metadata={\"help\": \"number of solutions to generate to compute the difficulty score\"})\n",
    "    \n",
    "@dataclass\n",
    "class QdArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.DataTrainingArguments\n",
    "    \"\"\"\n",
    "\n",
    "    a: str = field(\n",
    "        default=\"/home/flowers/work/hf/Qwen2.5-Coder-3B-Instruct\",\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "\n",
    "@dataclass\n",
    "class LLMArguments:\n",
    "    \"\"\"\n",
    "    Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.DataTrainingArguments\n",
    "    \"\"\"\n",
    "\n",
    "    model_name_or_path: str = field(\n",
    "        default=\"/home/flowers/work/hf/Qwen2.5-0.5B-Instruct\",\n",
    "        metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
    "    )\n",
    "    online: Optional[bool] = field(\n",
    "        default = False,\n",
    "        metadata={\n",
    "            \"help\": \"use vllm server if True else use offline vllm\"\n",
    "        },\n",
    "    )\n",
    "    base_url: Optional[str] = field(\n",
    "        default=\"http://localhost:8000\",\n",
    "        metadata={\n",
    "            \"help\": \"base url for vllm server\"\n",
    "        },\n",
    "    )\n",
    "    api_key: Optional[str] = field(\n",
    "        default=\"\",\n",
    "        metadata={\n",
    "            \"help\": \"api key \"\n",
    "        },\n",
    "    )\n",
    "    gpu: Optional[bool] = field(\n",
    "        default = 1,\n",
    "        metadata={\n",
    "            \"help\": \"number of gpus to use (vllm)\"\n",
    "        },\n",
    "    )\n",
    "    cfg_generation : Optional[bool] = field(\n",
    "        default = False,\n",
    "        metadata={\n",
    "            \"help\": \"use cfg generation\"\n",
    "        },\n",
    "    ),\n",
    "    temperature: Optional[float] = field(\n",
    "        default = 1.0,\n",
    "        metadata={\n",
    "            \"help\": \"temperature\"\n",
    "        },\n",
    "    )\n",
    "    max_tokens: Optional[int] = field(\n",
    "        default = 4000,\n",
    "        metadata={\n",
    "            \"help\": \"max tokens\"\n",
    "        },\n",
    "    )\n",
    "    max_model_length: Optional[int] = field(\n",
    "        default = 20000,\n",
    "        metadata={\n",
    "            \"help\": \"max context size\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "# parser = HfArgumentParser((AcesArguments,QdArguments,LLMArguments))\n",
    "# model_args, data_args, training_args = parser.parse_args_into_dataclasses()#[\"--output_dir\", \"/home/flowers/work/hf/trained/\"])\n",
    "aces_args, qd_args, llm_args = AcesArguments(), QdArguments(), LLMArguments()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "init LLM client\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:SEND Error: Host unreachable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-01 22:09:07 config.py:350] This model supports multiple tasks: {'generate', 'embedding'}. Defaulting to 'generate'.\n",
      "INFO 12-01 22:09:07 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='/home/flowers/work/hf/Qwen2.5-0.5B-Instruct', speculative_config=None, tokenizer='/home/flowers/work/hf/Qwen2.5-0.5B-Instruct', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=20000, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=/home/flowers/work/hf/Qwen2.5-0.5B-Instruct, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=True, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
      "INFO 12-01 22:09:07 selector.py:135] Using Flash Attention backend.\n",
      "INFO 12-01 22:09:07 model_runner.py:1072] Starting to load model /home/flowers/work/hf/Qwen2.5-0.5B-Instruct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6967f9d4c940a797cfe0aa9c86a03f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 12-01 22:09:08 model_runner.py:1077] Loading model weights took 0.9276 GB\n",
      "INFO 12-01 22:09:08 worker.py:232] Memory profiling results: total_gpu_memory=15.70GiB initial_memory_usage=1.31GiB peak_torch_memory=2.35GiB memory_usage_post_profile=1.34GiB non_torch_memory=0.41GiB kv_cache_size=11.37GiB gpu_memory_utilization=0.90\n",
      "INFO 12-01 22:09:08 gpu_executor.py:113] # GPU blocks: 62111, # CPU blocks: 21845\n",
      "INFO 12-01 22:09:08 gpu_executor.py:117] Maximum concurrency for 20000 tokens per request: 49.69x\n",
      "INFO 12-01 22:09:10 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 12-01 22:09:10 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 12-01 22:09:17 model_runner.py:1518] Graph capturing finished in 7 secs, took 0.15 GiB\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from typing import List, Dict\n",
    "from aces.llm_client import LLMClient\n",
    "from dataclasses import dataclass, field\n",
    "import json\n",
    "from aces.environement.p3.p3_genotype import P3\n",
    "from aces.environement.p3.prompt_function import get_prompt_label_p3, get_prompt_description_p3, prompt_solve_puzzle_given_f\n",
    "from aces.environement.p3.skill_list import skill_list\n",
    "from aces.environement.p3.utils import extract_skill, extract_solution, extract_f\n",
    "from aces.code_sandbox import evaluate, pass_at_k\n",
    "import numpy as np\n",
    "#TODO inherite from base ACES class with common stuff\n",
    "class ACES_p3:\n",
    "    def __init__(self, AcesArguments: dataclass, LLMArguments : dataclass):\n",
    "        # initialize LLM client\n",
    "        self.llm_args = LLMArguments\n",
    "        self.skill_list = skill_list\n",
    "\n",
    "        self.init_llm()\n",
    "        # initialize environment\n",
    "        self.aces_args = AcesArguments \n",
    "        self.initialize_environment()\n",
    "        self.archive = []\n",
    "        self.semantic_descriptors = []\n",
    "\n",
    "    def init_llm(self,) -> None:\n",
    "        \"\"\"init LLM client\"\"\"\n",
    "        print(\"init LLM client\")\n",
    "        cfg_generation ={\"model\": self.llm_args.model_name_or_path, \"temperature\": self.llm_args.temperature,  \"max_tokens\": self.llm_args.max_tokens}\n",
    "\n",
    "        self.llm = LLMClient(model = self.llm_args.model_name_or_path, \n",
    "                             cfg_generation = cfg_generation,\n",
    "                             base_url = self.llm_args.base_url, \n",
    "                             api_key = self.llm_args.api_key, \n",
    "                             online = self.llm_args.online, \n",
    "                             gpu = self.llm_args.gpu,\n",
    "                             max_model_length = self.llm_args.max_model_length)\n",
    "        print(\"LLM client initialized\")\n",
    "    \n",
    "    def initialize_environment(self) -> None:\n",
    "        with open(self.aces_args.path_archive, 'r') as f:\n",
    "            self.archives = json.load(f)\n",
    "        list_p3 = []\n",
    "\n",
    "        # generate semantic descriptor\n",
    "        for p in self.archives:\n",
    "            list_p3.append(P3(program_str = p['program_str']))\n",
    "        list_p3 = self.generate_semantic_descriptors(list_p3)\n",
    "        \n",
    "        # generate dfficulty\n",
    "        ## generate multiple solutions\n",
    "        list_p3 = self.generate_multiple_solutions(list_p3)\n",
    "        ## evaluate python code\n",
    "        list_p3 = self.evaluate_python_code(list_p3)\n",
    "        ## generate description\n",
    "        list_p3 = self.generate_description(list_p3)\n",
    "        self.archives = list_p3\n",
    "\n",
    "    def generate_multiple_solutions(self, puzzles: list[P3]) -> List[P3]:\n",
    "        \"\"\"Use LLM to generate multiple solutions for a list of puzzle\"\"\"\n",
    "        list_prompt_sol = []\n",
    "        for p in puzzles:\n",
    "            list_prompt_sol.append(prompt_solve_puzzle_given_f(p.program_str))\n",
    "        list_solutions = self.llm.multiple_completion(list_prompt_sol,n = self.aces_args.num_solutions)\n",
    "        for id_puzzle in range(len(puzzles)):\n",
    "            problem = puzzles[id_puzzle].program_str \n",
    "            n_solutions = [self.process_solutions(solution=sol,problem=problem) for sol in list_solutions[id_puzzle].response]\n",
    "            puzzles[id_puzzle].all_solution = n_solutions\n",
    "        # verify solution with python\n",
    "        return list_solutions\n",
    "    \n",
    "    def process_solutions(self, solution: str, problem: str) -> str: \n",
    "        \"\"\"Process solution and return full puzzle (f+g)\"\"\"\n",
    "        puzzle = extract_f(problem) + \"\\n\" + extract_solution(solution)\n",
    "        puzzle = puzzle.split(\"\\nassert f\")\n",
    "        puzzle = puzzle[0] + \"\\nassert f(g()) == True\\n\"\n",
    "\n",
    "    def evaluate_python_code(self, puzzles: list[P3]) -> List[P3]:\n",
    "        \"\"\"Evaluate python code\"\"\"\n",
    "        list_task_id = []\n",
    "        list_task_id_unique = []\n",
    "        list_codes_to_test = []\n",
    "        str_to_add=str(\n",
    "                    f\"\\ndef run_eval():\\n\"\n",
    "                    f\"    return f(g()) == True\"\n",
    "                )\n",
    "        for id_puz,p in enumerate(puzzles):\n",
    "            list_task_id_unique.append(id_puz)\n",
    "            for id_sol in range(len(p.all_solution)):\n",
    "                list_task_id.append(id_puz)\n",
    "                list_codes_to_test.append(p.all_solution[id_sol] + str_to_add)\n",
    "\n",
    "\n",
    "        results = evaluate(list_codes_to_test, list_task_id, entry_point=\"run_eval\")\n",
    "        # dic_passk = results[\"pass@k\"] # {task_id: pass@k} \n",
    "        raw_result = results[\"raw_result\"] \n",
    "        for task_id in list_task_id_unique:\n",
    "            all_solution = []\n",
    "            all_solution_correct = []\n",
    "            for id_completion in range(len(raw_result[task_id])):\n",
    "                all_solution.append(raw_result[task_id][id_completion][\"code\"].split(str_to_add)[0])\n",
    "                all_solution_correct.append(raw_result[task_id][id_completion][\"correct\"])\n",
    "            \n",
    "            puzzles[task_id].all_solution = all_solution\n",
    "            puzzles[task_id].all_solution_correct = all_solution_correct\n",
    "\n",
    "            number_solution = len(all_solution)\n",
    "            c = sum(all_solution_correct)\n",
    "            k=1 # estimation of pass@1\n",
    "            \n",
    "            if c==0:\n",
    "                fitness = -np.inf\n",
    "            else:\n",
    "                fitness = pass_at_k(n=number_solution, c=c, k=k)\n",
    "                list_correct_solution = [all_solution[i] for i in range(len(all_solution)) if all_solution_correct[i]]\n",
    "                id_rd = random.randint(0,len(list_correct_solution)-1)\n",
    "                puzzles[task_id].program_str = list_correct_solution[id_rd]\n",
    "            puzzles[task_id].fitness = fitness\n",
    "\n",
    "        return puzzles\n",
    "    \n",
    "\n",
    "    def generate_semantic_descriptors(self, puzzles: list[P3]) -> list[P3]:\n",
    "        # Use LLM to evaluate puzzle along N programming skill dimensions\n",
    "        # get prompt\n",
    "        list_prompt = []\n",
    "        for p in puzzles:\n",
    "            list_prompt.append(get_prompt_label_p3(p.program_str, self.skill_list))\n",
    "        list_skills = self.llm.multiple_completion(list_prompt)\n",
    "        for i in range(len(puzzles)):\n",
    "            skill, explanation_skill = extract_skill(list_skills[i].response[0])\n",
    "            puzzles[i].emb = skill\n",
    "            puzzles[i].explanation_emb = explanation_skill\n",
    "            # puzzle[i].phenotype = skill\n",
    "        return puzzles\n",
    "    \n",
    "    def generate_description(self, puzzles: list[P3]) -> list[P3]:\n",
    "        # Use LLM to evaluate puzzle along N programming skill dimensions\n",
    "        # get prompt\n",
    "        list_prompt = []\n",
    "        for p in puzzles:\n",
    "            list_prompt.append(get_prompt_description_p3(p.program_str))\n",
    "        list_description = self.llm.multiple_completion(list_prompt)\n",
    "        for i in range(len(puzzles)):\n",
    "            puzzles[i].description = list_description[i].response[0]\n",
    "        return puzzles\n",
    "    \n",
    "    def explore(self, num_iterations: int):\n",
    "        for _ in range(num_iterations):\n",
    "            # Generate novel target in semantic space\n",
    "            target_descriptors = self.generate_novel_target()\n",
    "            \n",
    "            # Generate puzzle matching target\n",
    "            candidate_puzzle = self.generate_puzzle(target_descriptors)\n",
    "            \n",
    "            # Verify feasibility\n",
    "            if self.evaluate_feasibility(candidate_puzzle):\n",
    "                actual_descriptors = self.generate_semantic_descriptors(candidate_puzzle)\n",
    "                self.generated_puzzles.append({\n",
    "                    'puzzle': candidate_puzzle,\n",
    "                    'descriptors': actual_descriptors\n",
    "                })\n",
    "\n",
    "    \n",
    "    def generate_novel_target(self) -> List[float]:\n",
    "        # Generate target that maximizes diversity from existing puzzles\n",
    "        #TODO: reproduce aces targeted\n",
    "        if not self.generated_puzzles:\n",
    "            return [random.random() for _ in range(self.num_dimensions)]\n",
    "            \n",
    "        # Find underexplored regions in semantic space\n",
    "        existing_descriptors = [p['descriptors'] for p in self.generated_puzzles]\n",
    "        target = self.find_diverse_target(existing_descriptors)\n",
    "        return target\n",
    "aces= ACES_p3(aces_args, llm_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,),\n",
       " (3, 4),\n",
       " (5,),\n",
       " (1, 2, 5),\n",
       " (2, 5),\n",
       " (1, 3),\n",
       " (1, 4, 5),\n",
       " (2, 4, 5),\n",
       " (4,),\n",
       " (1,),\n",
       " (4, 5),\n",
       " (1, 2, 4),\n",
       " (2, 4),\n",
       " (1, 2),\n",
       " (1, 5),\n",
       " (1, 3, 5),\n",
       " (2, 3, 5),\n",
       " (3,),\n",
       " (3, 5),\n",
       " (1, 2, 3),\n",
       " (1, 4),\n",
       " (1, 3, 4),\n",
       " (2, 3),\n",
       " (3, 4, 5),\n",
       " (2, 3, 4)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "n_skills = 5\n",
    "skills = list(range(1, n_skills+1))\n",
    "# Generate all combinations of up to 5 skills\n",
    "skill_combinations = set()\n",
    "for r in range(1, 3+1):  # From 1 skill to 5 skills\n",
    "    skill_combinations.update(combinations(skills, r))\n",
    "skill_combinations = list(skill_combinations)\n",
    "skill_combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(\u001b[38;5;28mlen\u001b[39m(skill_combinations),size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mskill_combinations\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      3\u001b[0m skill_targeted \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m out \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_skills)]\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "idx = np.random.choice(len(skill_combinations),size=1)\n",
    "out = skill_combinations[idx]\n",
    "skill_targeted = [1 if i in out else 0 for i in range(n_skills)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "200/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a[tuple(b)]=1\n",
    "a[tuple(c)]=2\n",
    "a[list(a.keys())[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aces.environement.p3.prompt_function import get_programming_puzzles_prompt\n",
    "from aces.environement.p3.p3_genotype import P3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3_1 = P3(program_str=\"puzzle test1\", emb=[1,0,1,0,0],fitness=0.5 )\n",
    "p3_2 = P3(program_str=\"puzzle test2\", emb=[1,0,1,0,0],fitness=0.5 )\n",
    "list_p3 = [p3_1, p3_2]\n",
    "skill_targeted=[1,0,1,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider Python Programming Puzzles (P3). P3 consists of two functions: a problem function `f` and its corresponding solution `g`. The challenge lies in constructing a SAT problem `f` and a function `g` such that `f(g())` evaluates to `True`\n",
      "\n",
      "## Main Rules:\n",
      "- Each puzzle includes two functions: `def f(...)` and `def g(...)`.\n",
      "- The first argument of `f` is always the output from `g()`.\n",
      "- Ensure `f` and `g` have matching argument signatures (e.g., `def f(solution, arg1=value1, arg2=value2, ...)` and `def g(arg1=value1, arg2=value2, ...)`). You also need to set the value of argument of f (arg1,arg2,...) and g when you define them.\n",
      "- Avoid using `f` inside `g`, and `g` inside `f`.\n",
      "- Include any necessary imports so your code runs smoothly.\n",
      "- Give a clear Puzzle description that must be brief and diverse compared to the other puzzles.\n",
      "- Make sure the puzzle is self-contained within these two functions.\n",
      "- Make sure that that each puzzle have just all required skills (see below)\n",
      "\n",
      "## P3 Format:\n",
      "Puzzle description: A two to four sentence summary of the puzzle's content. To explain what is the problem `f`, and how you can solve it with `g`. \n",
      "```python\n",
      "def f(solution, args=...) -> bool:\n",
      "    # Python code to test the solution returned by g.\n",
      "    # This function is a test unit and must return True if the solution is correct, and False otherwise.\n",
      "\n",
      "def g(args=...) -> solution:\n",
      "    # Python code to generate a solution for the problem.\n",
      "    # The solution should generalize to all possible args.\n",
      "    return solution\n",
      "\n",
      "assert f(g()) == True\n",
      "```\n",
      "\n",
      "## Examples:\n",
      "\n",
      "Puzzle 0:\n",
      "Puzzle description:  description of the puzzle\n",
      "\n",
      "- Difficulty score: 150 out of 100\n",
      "\n",
      "- This puzzle has the following skills:\n",
      "* String Manipulation\n",
      "* Conditional Logic\n",
      "\n",
      "```python\n",
      "puzzle test1\n",
      "```\n",
      "\n",
      "Puzzle 1:\n",
      "Puzzle description:  description of the puzzle\n",
      "\n",
      "- Difficulty score: 150 out of 100\n",
      "\n",
      "- This puzzle has the following skills:\n",
      "* String Manipulation\n",
      "* Conditional Logic\n",
      "\n",
      "```python\n",
      "puzzle test2\n",
      "```\n",
      "\n",
      "\n",
      "Generate 5 P3 similar to previous Examples. Ensure that all new puzzles are more challenging than Puzzle from previous examples.\n",
      "You should aim to generate puzzles with a Difficulty score between 90 and 100 out of 100.\n",
      "\n",
      "**Please make sure that new puzzles have JUST ALL the following skills**:\n",
      "- String Manipulation\n",
      "- Conditional Logic\n",
      "- Brute Force Search\n",
      "## New 5 problems:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(get_programming_puzzles_prompt(list_p3,skill_targeted,n_fewshot_ex=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path=\"/home/flowers/work/aces/aces/environement/p3/preprocess_p3_emb_dedup_puzzles.json\"\n",
    "with open(path, 'r') as f:\n",
    "    data = json.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'program_str': 'def f(n: int) -> bool:\\n    return str(n * n).startswith(\\'123456789\\')\\ndef g():\\n    return int(int(\"123456789\" + \"0\" * 9) ** 0.5) + 1\\nassert f(g()) == True',\n",
       " 'emb': [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       " 'explanation_emb': 'This puzzle involves string manipulation to check if the square of a number starts with a specific sequence of digits, and mathematical operations to calculate the square root of a number. The puzzle also requires an understanding of number theory, specifically the concept of square roots.\\n\\nThe list of skills used is: [0, 1, 16].',\n",
       " 'description': \"Find the solution: n (an integer) that should be squared and its result in string format starts with '123456789'.\",\n",
       " 'quality': 1,\n",
       " 'fitness': -0.020000000000000018,\n",
       " 'all_solution': ['def f(n: int) -> bool:\\n    return str(n * n).startswith(\\'123456789\\')\\ndef g():\\n    return int(int(\"123456789\" + \"0\" * 9) ** 0.5) + 1\\nassert f(g()) == True\\nassert f(g()) == True',\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294091\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294091\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294091\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3528439\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3528439\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294091\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3528439\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3528439\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3528439\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    i = 1\\n    while True:\\n        if str(i * i).startswith('123456789'):\\n            return i * i\\n        i += 1\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35265625\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    i = 1\\n    while True:\\n        if f(i):\\n            return i\\n        i += 1\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    i = 1\\n    while True:\\n        if f(i):\\n            return i\\n        i += 1\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000):\\n        if f(i):\\n            return i\\n    return None\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(10**9):\\n        if f(i):\\n            return i\\n    return None\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35265625\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(10000000):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    i = 1\\n    while True:\\n        if str(i * i).startswith('123456789'):\\n            return i * i\\n        i += 1\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35265609\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 352016843\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35265609 \\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294091  # or any other number that satisfies the condition\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(10**10):\\n        if f(i):\\n            return i\\n    return None\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 351843717\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    n = 352281\\n    return n\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35422436\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35265609 \\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 352656095\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3_210_196\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 352656357\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 3526560903\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 35429409164768\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    n = 35184372  # This is the smallest number whose square starts with '123456789'\\n    return n\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    for i in range(1000000000):\\n        if f(i):\\n            return i\\n    return -1  # or any default value\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 352651638\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    i = 0\\n    while True:\\n        i += 1\\n        if f(i):\\n            return i \\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354295736\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    import math\\n    n = 3526560929\\n    return n\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 352651358786\\n\\nassert f(g()) == True\\nassert f(g()) == True\",\n",
       "  \"def f(n: int) -> bool:\\n    return str(n * n).startswith('123456789')\\ndef g():\\n    return 354294）\\r\\n<|start_header_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nThis solution is correct because 354294^2 = 125235366561096 which starts with '123456789'.\\nassert f(g()) == True\\nassert f(g()) == True\"],\n",
       " 'all_solution_correct': [True,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False,\n",
       "  False],\n",
       " 'unique_id': 'P3_train-0'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]\n",
    "# suppose we only have \"program_str\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 394.90it/s]\n"
     ]
    }
   ],
   "source": [
    "from aces.code_sandbox import evaluate, pass_at_k\n",
    "str_to_add=str(\n",
    "            f\"\\ndef run_eval():\\n\"\n",
    "            f\"    return f(g()) == True\"\n",
    "        )\n",
    "\n",
    "list_codes=[\"def f(x):\\n    return x\\ndef g():\\n    return True\", \"def f(x):\\n    return x\\ndef g():\\n    return False\",\n",
    "            \"def f(x):\\n    return not x\\ndef g():\\n    return False\", \"def f(x):\\n    return not x\\ndef g():\\n    return True\"]\n",
    "\n",
    "\n",
    "list_task_id=[0,0,1,1]\n",
    "for i in range(len(list_codes)):\n",
    "    list_codes[i] = list_codes[i]+str_to_add\n",
    "\n",
    "res = evaluate(list_codes, list_task_id,entry_point=\"run_eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def rm_function(code, list_function_name):\n",
    "        # Parse the solution code to an AST\n",
    "    solution_ast = ast.parse(code)\n",
    "\n",
    "    # Filter out functions from the code that are in the list_function_name\n",
    "    filtered_body = [\n",
    "        node for node in solution_ast.body\n",
    "        if not isinstance(node, ast.FunctionDef) or node.name not in list_function_name\n",
    "    ]\n",
    "    # Create a new module with the filtered body\n",
    "    new_solution_ast = ast.Module(body=filtered_body, type_ignores=[])\n",
    "\n",
    "    # Convert the AST back to source code\n",
    "    new_solution_code = ast.unparse(new_solution_ast)\n",
    "    return new_solution_code\n",
    "\n",
    "\n",
    "a=\"\"\"\n",
    "import numpy as np\n",
    "def lcm(a, b):\n",
    "    return a * b // gcd(a, b)\n",
    "\n",
    "def f(n: int) -> bool:\n",
    "    for i in range(1, n // 2 + 1):\n",
    "        for j in range(i + 1, (n - i) // 2 + 1):\n",
    "            k = n - i - j\n",
    "            if k > j and lcm(k, lcm(i, j)) < 200:\n",
    "                return True\n",
    "    return False\n",
    "from typing import *\n",
    "\n",
    "def g():\n",
    "    # We need to find a value of n that satisfies the condition in the problem statement.\n",
    "    # A suitable n that works is 10 because:\n",
    "    # f(10) is true because there is a combination of (2, 8) and (1, 9) that satisfies the condition.\n",
    "\n",
    "    return 10\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\n\\ndef lcm(a, b):\\n    return a * b // gcd(a, b)\\nfrom typing import *'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rm_function(a,[\"f\",\"g\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_task_id=[0,1]\n",
    "for task_id in list_task_id:\n",
    "    all_solution = []\n",
    "    all_solution_correct = []\n",
    "    for id_completion in range(len(res[\"raw_result\"][task_id])):\n",
    "        all_solution.append(res[\"raw_result\"][task_id][id_completion][\"code\"].split(str_to_add)[0])\n",
    "        all_solution_correct.append(res[\"raw_result\"][task_id][id_completion][\"correct\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def f(x):\\n    return not x\\ndef g():\\n    return False',\n",
       " 'def f(x):\\n    return not x\\ndef g():\\n    return True']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_solution_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_solution = len(all_solution)\n",
    "c = sum(all_solution_correct)\n",
    "k=1\n",
    "pass_at_k(n=number_solution, c=c, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'task_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m id_completion \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 2\u001b[0m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_result\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[43mtask_id\u001b[49m][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(str_to_add)[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'task_id' is not defined"
     ]
    }
   ],
   "source": [
    "id_completion = 0\n",
    "res[\"raw_result\"][task_id][0][\"code\"].split(str_to_add)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[\"raw_result\"][0][0][\"correct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lcm', 'f', 'g']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how to get the name of all the function in a\n",
    "a=\"\"\"\n",
    "def lcm(a, b):\n",
    "    return a * b // gcd(a, b)\n",
    "\n",
    "def f(n: int) -> bool:\n",
    "    for i in range(1, n // 2 + 1):\n",
    "        for j in range(i + 1, (n - i) // 2 + 1):\n",
    "            k = n - i - j\n",
    "            if k > j and lcm(k, lcm(i, j)) < 200:\n",
    "                return True\n",
    "    return False\n",
    "from typing import *\n",
    "\n",
    "def g():\n",
    "    # We need to find a value of n that satisfies the condition in the problem statement.\n",
    "    # A suitable n that works is 10 because:\n",
    "    # f(10) is true because there is a combination of (2, 8) and (1, 9) that satisfies the condition.\n",
    "\n",
    "    return 10\n",
    "\"\"\"\n",
    "import ast\n",
    "\n",
    "# Parse the code string into an AST\n",
    "parsed_code = ast.parse(a)\n",
    "\n",
    "# Extract function names using list comprehension\n",
    "function_names = [node.name for node in parsed_code.body if isinstance(node, ast.FunctionDef)]\n",
    "\n",
    "function_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mg\u001b[39m(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, s\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRObAQuYK\u001b[39m\u001b[38;5;124m'\u001b[39m, t\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrobaQUYKkuLY\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m<\u001b[39m t\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m f(g()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def f(n: int, s='RObAQuYK', t='robaQUYKkuLY') -> bool:\n",
    "    if n == 0:\n",
    "        return s.lower() == t.lower()\n",
    "    if n == 1:\n",
    "        return s.lower() > t.lower()\n",
    "    if n == -1:\n",
    "        return s.lower() < t.lower()\n",
    "    return False\n",
    "def g(s = 'RObAQuYK', t = 'robaQUYKkuLY'):\n",
    "    if s.lower() == t.lower():\n",
    "        return 0\n",
    "    if s.lower() > t.lower():\n",
    "        return 1\n",
    "    return -1\n",
    "assert f(g()) == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aces",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
